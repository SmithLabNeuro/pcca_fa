{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial for utilizing pCCA-FA for neural population activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# add path to where dependencies are stored (FA and CCA)\n",
    "# ensure codes are in folders named \"fa\" and \"cca\", respectively\n",
    "sys.path.append('../')\n",
    "\n",
    "# Imports and params\n",
    "import numpy as np\n",
    "import pcca_fa_mdl as pf\n",
    "import sim_pcca_fa as spf\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# random seed for reproducibility\n",
    "rand_seed = 10\n",
    "\n",
    "# plot colors\n",
    "color_map = {\n",
    "    'across':np.array([255,76,178])/255, # pink\n",
    "    'within1':np.array([111,192,255])/255, # light blue - right hemisphere\n",
    "    'within2':np.array([0,87,154])/255, # dark blue - left hemisphere\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need data that will be fed into the pCCA-FA model. In the following cell, we will simulate data according to the generative model specifed by pCCA-FA to use. But, any two spike count matrices with size (number_of_observations x number_of_neurons) can be used in place of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for simulating data\n",
    "xDim,yDim = 30,30 # this parameter indicates the number of neurons in area X and area Y\n",
    "zDim,zxDim,zyDim = 3,2,1 # this parameter indicates the number of latent variables for across-area, within-area X, and within-area Y\n",
    "n_trials = 5000 # number of trials or observations\n",
    "\n",
    "# simulate data according to generative model pCCA-FA\n",
    "pf_simulator = spf.sim_pcca_fa(xDim,yDim,zDim,zxDim,zyDim,rand_seed=rand_seed)\n",
    "X,Y = pf_simulator.sim_data(n_trials,rand_seed=rand_seed)\n",
    "sim_params = pf_simulator.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the variables X and Y represent our two areas' spike count matrices. Each has dimensionality (number_of_observations x number_of_neurons). The next step is to fit the model. We need to decide which latent dimensionalities to test. This will correspond to the dimensionality of latent variables tested during model cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select dimensionalities to test, needs to be a list of integers\n",
    "zDim_list = np.arange(0,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get to train the model! First, we initialize it, then fit it by cross-validating the latent dimensionalities for within- and across-area dimensions. Note, this takes a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model = pf.pcca_fa()\n",
    "start = timer()\n",
    "LL_curves = model.crossvalidate(X,Y,rand_seed=rand_seed,verbose=True,zDim_list=zDim_list,zxDim_list=zDim_list,zyDim_list=zDim_list,parallelize=True,n_folds=5)\n",
    "end = timer()\n",
    "cv_z,cv_zx,cv_zy = LL_curves['zDim'],LL_curves['zxDim'],LL_curves['zyDim']\n",
    "print(f'{end-start:.2f} seconds elapsed...')\n",
    "print(f'Identified dimensionalities - across-area: {cv_z:d}, within-area X: {cv_zx:d}, within-area Y: {cv_zy:d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In place of cross-validating (or after we have completed a round of cross-validation), we can save time by simply fitting a model of given dimensionality. We can do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pf.pcca_fa()\n",
    "start = timer()\n",
    "model.train(X,Y,zDim,zxDim,zyDim)\n",
    "end = timer()\n",
    "print(f'{end-start:.2f} seconds elapsed...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a model fit. What does it all mean? model_params is a dictionary where each key is a parameter name of the model, and each value is the fit value of that parameter. <br>\n",
    "<b>mu</b>: mean firing rate for each neuron <br>\n",
    "<b>L_total</b>: combined loadings for across- and within-area latent variables <br>\n",
    "<b>W</b>: loadings for across-area variance for each neuron and each across-area latent variable <br>\n",
    "<b>L</b>: loadings for within-area variance for each neuron and each within-area latent variable <br>\n",
    "<b>psi</b>: independent variance of each neuron <br>\n",
    "<b>zDim</b>: dimensionality for across-area <br>\n",
    "<b>zxDim</b>: dimensionality for within-area x <br>\n",
    "<b>zyDim</b>: dimensionality for within-area y <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = model.get_params()\n",
    "print(model_params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute data metrics using the model, such as the shared variance explained by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics - from ground truth parameters\n",
    "sim_model = pf.pcca_fa()\n",
    "sim_model.set_params(sim_params)\n",
    "true_psv = sim_model.compute_metrics(cutoff_thresh=0.95)['psv']\n",
    "\n",
    "# compute cross-validated percent of shared variance using bootstrapping\n",
    "train_psv,test_psv = model.compute_cv_psv(X,Y,zDim,zxDim,zyDim,n_boots=50,rand_seed=rand_seed,return_each=True,test_size=0.1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "pad = 3\n",
    "fig,ax = plt.subplots(2,2, tight_layout=True, sharex=True)\n",
    "\n",
    "ax[0,0].errorbar(1,np.mean(train_psv['psv_x']),yerr=np.std(train_psv['psv_x']),fmt='o',label='training',color=color_map['across'])\n",
    "ax[0,0].errorbar(2,np.mean(test_psv['psv_x']),yerr=np.std(test_psv['psv_x']),fmt='o',label='heldout',color=color_map['across'])\n",
    "ax[0,0].set_xlim([0.5,2.5])\n",
    "ax[0,0].set_ylim([true_psv['psv_x']-pad,true_psv['psv_x']+pad])\n",
    "ax[0,0].plot(ax[0,0].get_xlim(),np.ones(2)*true_psv['psv_x'],'k--',label='true')\n",
    "ax[0,0].set_ylabel('across-area %sv', color=color_map['across'])\n",
    "ax[0,0].set_xticks([])\n",
    "ax[0,0].set_title('area 1')\n",
    "\n",
    "ax[0,1].errorbar(1,np.mean(train_psv['psv_priv_x']),yerr=np.std(train_psv['psv_priv_x']),fmt='o',label='training',color=color_map['within1'])\n",
    "ax[0,1].errorbar(2,np.mean(test_psv['psv_priv_x']),yerr=np.std(test_psv['psv_priv_x']),fmt='o',label='heldout',color=color_map['within1'])\n",
    "ax[0,1].set_xlim([0.5,2.5])\n",
    "ax[0,1].set_ylim([true_psv['psv_priv_x']-pad,true_psv['psv_priv_x']+pad])\n",
    "ax[0,1].plot(ax[0,1].get_xlim(),np.ones(2)*true_psv['psv_priv_x'],'k--',label='true')\n",
    "ax[0,1].set_ylabel('within-area %sv', color=color_map['within1'])\n",
    "ax[0,1].set_xticks([])\n",
    "ax[0,1].set_title('area 1')\n",
    "\n",
    "ax[1,0].errorbar(1,np.mean(train_psv['psv_y']),yerr=np.std(train_psv['psv_y']),fmt='o',label='training',color=color_map['across'])\n",
    "ax[1,0].errorbar(2,np.mean(test_psv['psv_y']),yerr=np.std(test_psv['psv_y']),fmt='o',label='heldout',color=color_map['across'])\n",
    "ax[1,0].set_xlim([0.5,2.5])\n",
    "ax[1,0].set_ylim([true_psv['psv_y']-pad,true_psv['psv_y']+pad])\n",
    "ax[1,0].plot(ax[1,0].get_xlim(),np.ones(2)*true_psv['psv_y'],'k--',label='true')\n",
    "ax[1,0].set_ylabel('across-area %sv', color=color_map['across'])\n",
    "ax[1,0].set_xticks([1,2])\n",
    "ax[1,0].set_xticklabels(['training','heldout'])\n",
    "ax[1,0].set_title('area 2')\n",
    "\n",
    "ax[1,1].errorbar(1,np.mean(train_psv['psv_priv_y']),yerr=np.std(train_psv['psv_priv_y']),fmt='o',label='training',color=color_map['within2'])\n",
    "ax[1,1].errorbar(2,np.mean(test_psv['psv_priv_y']),yerr=np.std(test_psv['psv_priv_y']),fmt='o',label='heldout',color=color_map['within2'])\n",
    "ax[1,1].set_xlim([0.5,2.5])\n",
    "ax[1,1].set_ylim([true_psv['psv_priv_y']-pad,true_psv['psv_priv_y']+pad])\n",
    "ax[1,1].plot(ax[1,1].get_xlim(),np.ones(2)*true_psv['psv_priv_y'],'k--',label='true')\n",
    "ax[1,1].set_ylabel('within-area %sv', color=color_map['within2'])\n",
    "ax[1,1].set_xticks([1,2])\n",
    "ax[1,1].set_xticklabels(['training','heldout'])\n",
    "ax[1,1].set_title('area 2')\n",
    "\n",
    "ax[0,0].legend()\n",
    "\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pCCA-FA parameters also yield the canonical correlations, as would be identified by applying traditional CCA to the neural activity. Using the model we trained, we can obtain the canonical directions and canonical correlations as defined in CCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(canonical_dirs_x, canonical_dirs_y), rho = model.get_canonical_directions()\n",
    "\n",
    "xdata = np.arange(zDim)+1\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(xdata, rho, marker='o', color='gray')\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel(r'canonical correlation ($\\rho$)')\n",
    "ax.set_xticks(xdata)\n",
    "ax.set_xlabel('canonical pair number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pccafa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
